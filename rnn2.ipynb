{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:42:51.101513Z",
     "start_time": "2017-11-22T04:42:49.831477Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, SimpleRNN, Dense, merge, Flatten, BatchNormalization, LSTM, TimeDistributed, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import urllib2\n",
    "import numpy as np\n",
    "\n",
    "dataset_raw = urllib2.urlopen(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\").read().\\\n",
    "    replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:42:54.886838Z",
     "start_time": "2017-11-22T04:42:54.841087Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = sorted(list(set([i for i in dataset_raw])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:42:55.349902Z",
     "start_time": "2017-11-22T04:42:55.347027Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:42:55.814979Z",
     "start_time": "2017-11-22T04:42:55.811092Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt_encoder = {v:k for k,v in enumerate(vocab)}\n",
    "txt_decoder = {k:v for k,v in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:42:56.579963Z",
     "start_time": "2017-11-22T04:42:56.526802Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_encoded = [txt_encoder[i] for i in dataset_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:42:57.232867Z",
     "start_time": "2017-11-22T04:42:57.230099Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:42:57.849905Z",
     "start_time": "2017-11-22T04:42:57.846820Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:43:04.196281Z",
     "start_time": "2017-11-22T04:43:03.087079Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = [np.stack([dataset_encoded[i + j] for i in range(0, len(dataset_raw) - seq_len - 1, seq_len)]) for j in range(seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:43:08.396199Z",
     "start_time": "2017-11-22T04:43:07.271671Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_data = [np.stack([dataset_encoded[i + j]\n",
    "                         for i in range(0, len(dataset_raw) - seq_len - 1, seq_len)])[:,np.newaxis] \n",
    "                         for j in range(1, seq_len + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:11:35.236825Z",
     "start_time": "2017-11-22T04:11:35.167154Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inps = []\n",
    "embs = []\n",
    "\n",
    "for i in range(seq_len):\n",
    "    inps.append(Input(shape=(1,), name='inp_%s' % i))\n",
    "    embs.append(Flatten()(Embedding(input_dim=vocab_size, output_dim=40, name='emb_%s' % i)(inps[i])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:11:36.095848Z",
     "start_time": "2017-11-22T04:11:36.092946Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:11:37.091237Z",
     "start_time": "2017-11-22T04:11:37.087073Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(hidden_layer_size, activation='relu')\n",
    "dense_hidden = Dense(hidden_layer_size, activation='relu', init='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:11:38.149028Z",
     "start_time": "2017-11-22T04:11:38.067045Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs = []\n",
    "\n",
    "zero_inp = Input(shape=(40,), name='zeros')\n",
    "hidden = dense_in(zero_inp)\n",
    "\n",
    "for i in range(seq_len):\n",
    "    bn = BatchNormalization()(embs[i])\n",
    "    din = dense_in(bn)\n",
    "    hidden = merge([din, dense_hidden(hidden)])\n",
    "    outs.append(dense_out(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:11:39.132653Z",
     "start_time": "2017-11-22T04:11:39.121053Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeros = np.tile(np.zeros(40), (len(train_data[0]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(len(train_data[0]),40))\n",
    "emb = Embedding(vocab_size, 60, input_length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:11:40.090767Z",
     "start_time": "2017-11-22T04:11:40.085256Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl = Model(input=[zero_inp] + [i for i in inps], output=outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:11:41.421275Z",
     "start_time": "2017-11-22T04:11:41.342738Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl.compile(optimizer=Adam(lr=0.00001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:08:35.190349Z",
     "start_time": "2017-11-21T22:04:30.438472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75112/75112 [==============================] - 15s - loss: 28.6928 - dense_3_loss_1: 4.2481 - dense_3_loss_2: 4.0295 - dense_3_loss_3: 3.7415 - dense_3_loss_4: 3.4701 - dense_3_loss_5: 3.3294 - dense_3_loss_6: 3.2722 - dense_3_loss_7: 3.2750 - dense_3_loss_8: 3.3271    \n",
      "Epoch 2/12\n",
      "75112/75112 [==============================] - 15s - loss: 25.7862 - dense_3_loss_1: 3.9131 - dense_3_loss_2: 3.5009 - dense_3_loss_3: 3.1995 - dense_3_loss_4: 3.0287 - dense_3_loss_5: 3.0105 - dense_3_loss_6: 3.0168 - dense_3_loss_7: 3.0476 - dense_3_loss_8: 3.0690    \n",
      "Epoch 3/12\n",
      "75112/75112 [==============================] - 15s - loss: 24.4473 - dense_3_loss_1: 3.6158 - dense_3_loss_2: 3.1935 - dense_3_loss_3: 3.0057 - dense_3_loss_4: 2.9193 - dense_3_loss_5: 2.9235 - dense_3_loss_6: 2.9200 - dense_3_loss_7: 2.9370 - dense_3_loss_8: 2.9325    \n",
      "Epoch 4/12\n",
      "75112/75112 [==============================] - 15s - loss: 23.3779 - dense_3_loss_1: 3.3494 - dense_3_loss_2: 2.9923 - dense_3_loss_3: 2.8867 - dense_3_loss_4: 2.8303 - dense_3_loss_5: 2.8400 - dense_3_loss_6: 2.8233 - dense_3_loss_7: 2.8334 - dense_3_loss_8: 2.8225    \n",
      "Epoch 5/12\n",
      "75112/75112 [==============================] - 15s - loss: 22.4873 - dense_3_loss_1: 3.1296 - dense_3_loss_2: 2.8581 - dense_3_loss_3: 2.7945 - dense_3_loss_4: 2.7477 - dense_3_loss_5: 2.7575 - dense_3_loss_6: 2.7326 - dense_3_loss_7: 2.7390 - dense_3_loss_8: 2.7283    \n",
      "Epoch 6/12\n",
      "75112/75112 [==============================] - 15s - loss: 21.7812 - dense_3_loss_1: 2.9648 - dense_3_loss_2: 2.7609 - dense_3_loss_3: 2.7164 - dense_3_loss_4: 2.6770 - dense_3_loss_5: 2.6836 - dense_3_loss_6: 2.6593 - dense_3_loss_7: 2.6637 - dense_3_loss_8: 2.6556    \n",
      "Epoch 7/12\n",
      "75112/75112 [==============================] - 15s - loss: 21.2460 - dense_3_loss_1: 2.8496 - dense_3_loss_2: 2.6878 - dense_3_loss_3: 2.6546 - dense_3_loss_4: 2.6198 - dense_3_loss_5: 2.6243 - dense_3_loss_6: 2.6034 - dense_3_loss_7: 2.6060 - dense_3_loss_8: 2.6005    \n",
      "Epoch 8/12\n",
      "75112/75112 [==============================] - 15s - loss: 20.8445 - dense_3_loss_1: 2.7716 - dense_3_loss_2: 2.6315 - dense_3_loss_3: 2.6061 - dense_3_loss_4: 2.5755 - dense_3_loss_5: 2.5772 - dense_3_loss_6: 2.5618 - dense_3_loss_7: 2.5639 - dense_3_loss_8: 2.5571    \n",
      "Epoch 9/12\n",
      "75112/75112 [==============================] - 15s - loss: 20.5406 - dense_3_loss_1: 2.7180 - dense_3_loss_2: 2.5910 - dense_3_loss_3: 2.5687 - dense_3_loss_4: 2.5394 - dense_3_loss_5: 2.5396 - dense_3_loss_6: 2.5283 - dense_3_loss_7: 2.5316 - dense_3_loss_8: 2.5240    \n",
      "Epoch 10/12\n",
      "75112/75112 [==============================] - 15s - loss: 20.2932 - dense_3_loss_1: 2.6796 - dense_3_loss_2: 2.5594 - dense_3_loss_3: 2.5375 - dense_3_loss_4: 2.5095 - dense_3_loss_5: 2.5094 - dense_3_loss_6: 2.4996 - dense_3_loss_7: 2.5039 - dense_3_loss_8: 2.4942    \n",
      "Epoch 11/12\n",
      "75112/75112 [==============================] - 15s - loss: 20.0910 - dense_3_loss_1: 2.6515 - dense_3_loss_2: 2.5352 - dense_3_loss_3: 2.5105 - dense_3_loss_4: 2.4844 - dense_3_loss_5: 2.4832 - dense_3_loss_6: 2.4758 - dense_3_loss_7: 2.4808 - dense_3_loss_8: 2.4696    \n",
      "Epoch 12/12\n",
      "75112/75112 [==============================] - 15s - loss: 19.9205 - dense_3_loss_1: 2.6292 - dense_3_loss_2: 2.5150 - dense_3_loss_3: 2.4881 - dense_3_loss_4: 2.4630 - dense_3_loss_5: 2.4617 - dense_3_loss_6: 2.4547 - dense_3_loss_7: 2.4608 - dense_3_loss_8: 2.4480    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8672b96590>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit([zeros] + train_data, output_data, nb_epoch=12, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:12:29.994836Z",
     "start_time": "2017-11-21T22:09:05.431145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75112/75112 [==============================] - 15s - loss: 19.3652 - dense_3_loss_1: 2.5690 - dense_3_loss_2: 2.4519 - dense_3_loss_3: 2.4105 - dense_3_loss_4: 2.3885 - dense_3_loss_5: 2.3888 - dense_3_loss_6: 2.3814 - dense_3_loss_7: 2.3944 - dense_3_loss_8: 2.3807    \n",
      "Epoch 2/12\n",
      "75112/75112 [==============================] - 15s - loss: 18.6464 - dense_3_loss_1: 2.5130 - dense_3_loss_2: 2.3812 - dense_3_loss_3: 2.3194 - dense_3_loss_4: 2.2896 - dense_3_loss_5: 2.2908 - dense_3_loss_6: 2.2800 - dense_3_loss_7: 2.2927 - dense_3_loss_8: 2.2797    \n",
      "Epoch 3/12\n",
      "75112/75112 [==============================] - 15s - loss: 18.1987 - dense_3_loss_1: 2.4889 - dense_3_loss_2: 2.3438 - dense_3_loss_3: 2.2663 - dense_3_loss_4: 2.2265 - dense_3_loss_5: 2.2253 - dense_3_loss_6: 2.2118 - dense_3_loss_7: 2.2259 - dense_3_loss_8: 2.2102    \n",
      "Epoch 4/12\n",
      "75112/75112 [==============================] - 15s - loss: 17.8806 - dense_3_loss_1: 2.4754 - dense_3_loss_2: 2.3204 - dense_3_loss_3: 2.2300 - dense_3_loss_4: 2.1831 - dense_3_loss_5: 2.1787 - dense_3_loss_6: 2.1593 - dense_3_loss_7: 2.1755 - dense_3_loss_8: 2.1582    \n",
      "Epoch 5/12\n",
      "75112/75112 [==============================] - 15s - loss: 17.6452 - dense_3_loss_1: 2.4673 - dense_3_loss_2: 2.3075 - dense_3_loss_3: 2.2044 - dense_3_loss_4: 2.1494 - dense_3_loss_5: 2.1413 - dense_3_loss_6: 2.1207 - dense_3_loss_7: 2.1365 - dense_3_loss_8: 2.1181    \n",
      "Epoch 6/12\n",
      "75112/75112 [==============================] - 15s - loss: 17.4623 - dense_3_loss_1: 2.4624 - dense_3_loss_2: 2.2976 - dense_3_loss_3: 2.1850 - dense_3_loss_4: 2.1242 - dense_3_loss_5: 2.1137 - dense_3_loss_6: 2.0903 - dense_3_loss_7: 2.1035 - dense_3_loss_8: 2.0855    \n",
      "Epoch 7/12\n",
      "75112/75112 [==============================] - 15s - loss: 17.3065 - dense_3_loss_1: 2.4579 - dense_3_loss_2: 2.2904 - dense_3_loss_3: 2.1674 - dense_3_loss_4: 2.1018 - dense_3_loss_5: 2.0895 - dense_3_loss_6: 2.0643 - dense_3_loss_7: 2.0773 - dense_3_loss_8: 2.0581    \n",
      "Epoch 8/12\n",
      "75112/75112 [==============================] - 15s - loss: 17.1732 - dense_3_loss_1: 2.4540 - dense_3_loss_2: 2.2858 - dense_3_loss_3: 2.1546 - dense_3_loss_4: 2.0840 - dense_3_loss_5: 2.0669 - dense_3_loss_6: 2.0414 - dense_3_loss_7: 2.0529 - dense_3_loss_8: 2.0336    \n",
      "Epoch 9/12\n",
      "75112/75112 [==============================] - 14s - loss: 17.0498 - dense_3_loss_1: 2.4521 - dense_3_loss_2: 2.2805 - dense_3_loss_3: 2.1414 - dense_3_loss_4: 2.0668 - dense_3_loss_5: 2.0481 - dense_3_loss_6: 2.0207 - dense_3_loss_7: 2.0304 - dense_3_loss_8: 2.0099    \n",
      "Epoch 10/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.9370 - dense_3_loss_1: 2.4493 - dense_3_loss_2: 2.2768 - dense_3_loss_3: 2.1310 - dense_3_loss_4: 2.0507 - dense_3_loss_5: 2.0279 - dense_3_loss_6: 2.0014 - dense_3_loss_7: 2.0105 - dense_3_loss_8: 1.9895    \n",
      "Epoch 11/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.8428 - dense_3_loss_1: 2.4488 - dense_3_loss_2: 2.2746 - dense_3_loss_3: 2.1229 - dense_3_loss_4: 2.0394 - dense_3_loss_5: 2.0116 - dense_3_loss_6: 1.9831 - dense_3_loss_7: 1.9914 - dense_3_loss_8: 1.9710    \n",
      "Epoch 12/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.7508 - dense_3_loss_1: 2.4461 - dense_3_loss_2: 2.2717 - dense_3_loss_3: 2.1148 - dense_3_loss_4: 2.0250 - dense_3_loss_5: 1.9974 - dense_3_loss_6: 1.9674 - dense_3_loss_7: 1.9753 - dense_3_loss_8: 1.9532    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f865e509490>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.compile(optimizer=Adam(lr=0.0001), loss='sparse_categorical_crossentropy')\n",
    "mdl.fit([zeros] + train_data, output_data, nb_epoch=12, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:24:37.760282Z",
     "start_time": "2017-11-21T22:21:20.993496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75112/75112 [==============================] - 15s - loss: 18.7042 - dense_3_loss_1: 2.5083 - dense_3_loss_2: 2.3797 - dense_3_loss_3: 2.3180 - dense_3_loss_4: 2.2843 - dense_3_loss_5: 2.3040 - dense_3_loss_6: 2.2955 - dense_3_loss_7: 2.3150 - dense_3_loss_8: 2.2993    \n",
      "Epoch 2/12\n",
      "75112/75112 [==============================] - 14s - loss: 17.4989 - dense_3_loss_1: 2.4632 - dense_3_loss_2: 2.3154 - dense_3_loss_3: 2.1877 - dense_3_loss_4: 2.1194 - dense_3_loss_5: 2.1143 - dense_3_loss_6: 2.0968 - dense_3_loss_7: 2.1094 - dense_3_loss_8: 2.0927    \n",
      "Epoch 3/12\n",
      "75112/75112 [==============================] - 14s - loss: 17.2581 - dense_3_loss_1: 2.4592 - dense_3_loss_2: 2.3099 - dense_3_loss_3: 2.1657 - dense_3_loss_4: 2.0840 - dense_3_loss_5: 2.0709 - dense_3_loss_6: 2.0515 - dense_3_loss_7: 2.0681 - dense_3_loss_8: 2.0488    \n",
      "Epoch 4/12\n",
      "75112/75112 [==============================] - 14s - loss: 17.0941 - dense_3_loss_1: 2.4557 - dense_3_loss_2: 2.3046 - dense_3_loss_3: 2.1515 - dense_3_loss_4: 2.0622 - dense_3_loss_5: 2.0410 - dense_3_loss_6: 2.0221 - dense_3_loss_7: 2.0380 - dense_3_loss_8: 2.0188    \n",
      "Epoch 5/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.9848 - dense_3_loss_1: 2.4520 - dense_3_loss_2: 2.3014 - dense_3_loss_3: 2.1413 - dense_3_loss_4: 2.0464 - dense_3_loss_5: 2.0252 - dense_3_loss_6: 2.0002 - dense_3_loss_7: 2.0189 - dense_3_loss_8: 1.9994    \n",
      "Epoch 6/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.9204 - dense_3_loss_1: 2.4502 - dense_3_loss_2: 2.2980 - dense_3_loss_3: 2.1360 - dense_3_loss_4: 2.0394 - dense_3_loss_5: 2.0153 - dense_3_loss_6: 1.9876 - dense_3_loss_7: 2.0059 - dense_3_loss_8: 1.9880    \n",
      "Epoch 7/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.8771 - dense_3_loss_1: 2.4505 - dense_3_loss_2: 2.2997 - dense_3_loss_3: 2.1326 - dense_3_loss_4: 2.0327 - dense_3_loss_5: 2.0061 - dense_3_loss_6: 1.9800 - dense_3_loss_7: 1.9977 - dense_3_loss_8: 1.9779    \n",
      "Epoch 8/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.8175 - dense_3_loss_1: 2.4492 - dense_3_loss_2: 2.2947 - dense_3_loss_3: 2.1264 - dense_3_loss_4: 2.0258 - dense_3_loss_5: 1.9980 - dense_3_loss_6: 1.9691 - dense_3_loss_7: 1.9862 - dense_3_loss_8: 1.9680    \n",
      "Epoch 9/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.7840 - dense_3_loss_1: 2.4485 - dense_3_loss_2: 2.2949 - dense_3_loss_3: 2.1264 - dense_3_loss_4: 2.0218 - dense_3_loss_5: 1.9901 - dense_3_loss_6: 1.9579 - dense_3_loss_7: 1.9797 - dense_3_loss_8: 1.9647    \n",
      "Epoch 10/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.7327 - dense_3_loss_1: 2.4478 - dense_3_loss_2: 2.2924 - dense_3_loss_3: 2.1228 - dense_3_loss_4: 2.0132 - dense_3_loss_5: 1.9827 - dense_3_loss_6: 1.9536 - dense_3_loss_7: 1.9705 - dense_3_loss_8: 1.9496    \n",
      "Epoch 11/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.7014 - dense_3_loss_1: 2.4463 - dense_3_loss_2: 2.2895 - dense_3_loss_3: 2.1212 - dense_3_loss_4: 2.0124 - dense_3_loss_5: 1.9764 - dense_3_loss_6: 1.9460 - dense_3_loss_7: 1.9615 - dense_3_loss_8: 1.9481    \n",
      "Epoch 12/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.6831 - dense_3_loss_1: 2.4467 - dense_3_loss_2: 2.2893 - dense_3_loss_3: 2.1207 - dense_3_loss_4: 2.0085 - dense_3_loss_5: 1.9748 - dense_3_loss_6: 1.9425 - dense_3_loss_7: 1.9604 - dense_3_loss_8: 1.9402    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f865a3911d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.compile(optimizer=Adam(lr=0.01), loss='sparse_categorical_crossentropy')\n",
    "mdl.fit([zeros] + train_data, output_data, nb_epoch=12, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:32:28.897568Z",
     "start_time": "2017-11-21T22:29:05.340836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.3331 - dense_3_loss_1: 2.4323 - dense_3_loss_2: 2.2662 - dense_3_loss_3: 2.0841 - dense_3_loss_4: 1.9621 - dense_3_loss_5: 1.9194 - dense_3_loss_6: 1.8863 - dense_3_loss_7: 1.9009 - dense_3_loss_8: 1.8819    \n",
      "Epoch 2/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.2417 - dense_3_loss_1: 2.4299 - dense_3_loss_2: 2.2624 - dense_3_loss_3: 2.0759 - dense_3_loss_4: 1.9511 - dense_3_loss_5: 1.9065 - dense_3_loss_6: 1.8687 - dense_3_loss_7: 1.8830 - dense_3_loss_8: 1.8642    \n",
      "Epoch 3/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.2094 - dense_3_loss_1: 2.4286 - dense_3_loss_2: 2.2617 - dense_3_loss_3: 2.0729 - dense_3_loss_4: 1.9471 - dense_3_loss_5: 1.9016 - dense_3_loss_6: 1.8637 - dense_3_loss_7: 1.8760 - dense_3_loss_8: 1.8580    \n",
      "Epoch 4/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.1919 - dense_3_loss_1: 2.4282 - dense_3_loss_2: 2.2610 - dense_3_loss_3: 2.0722 - dense_3_loss_4: 1.9450 - dense_3_loss_5: 1.8993 - dense_3_loss_6: 1.8602 - dense_3_loss_7: 1.8721 - dense_3_loss_8: 1.8537    \n",
      "Epoch 5/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.1733 - dense_3_loss_1: 2.4279 - dense_3_loss_2: 2.2602 - dense_3_loss_3: 2.0712 - dense_3_loss_4: 1.9429 - dense_3_loss_5: 1.8960 - dense_3_loss_6: 1.8564 - dense_3_loss_7: 1.8692 - dense_3_loss_8: 1.8495    \n",
      "Epoch 6/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.1602 - dense_3_loss_1: 2.4274 - dense_3_loss_2: 2.2596 - dense_3_loss_3: 2.0704 - dense_3_loss_4: 1.9411 - dense_3_loss_5: 1.8943 - dense_3_loss_6: 1.8547 - dense_3_loss_7: 1.8668 - dense_3_loss_8: 1.8459    \n",
      "Epoch 7/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.1485 - dense_3_loss_1: 2.4271 - dense_3_loss_2: 2.2595 - dense_3_loss_3: 2.0698 - dense_3_loss_4: 1.9391 - dense_3_loss_5: 1.8922 - dense_3_loss_6: 1.8521 - dense_3_loss_7: 1.8649 - dense_3_loss_8: 1.8437    \n",
      "Epoch 8/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.1352 - dense_3_loss_1: 2.4271 - dense_3_loss_2: 2.2593 - dense_3_loss_3: 2.0689 - dense_3_loss_4: 1.9381 - dense_3_loss_5: 1.8903 - dense_3_loss_6: 1.8496 - dense_3_loss_7: 1.8621 - dense_3_loss_8: 1.8399    \n",
      "Epoch 9/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.1264 - dense_3_loss_1: 2.4266 - dense_3_loss_2: 2.2589 - dense_3_loss_3: 2.0683 - dense_3_loss_4: 1.9372 - dense_3_loss_5: 1.8897 - dense_3_loss_6: 1.8476 - dense_3_loss_7: 1.8594 - dense_3_loss_8: 1.8386    \n",
      "Epoch 10/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.1162 - dense_3_loss_1: 2.4263 - dense_3_loss_2: 2.2590 - dense_3_loss_3: 2.0683 - dense_3_loss_4: 1.9353 - dense_3_loss_5: 1.8877 - dense_3_loss_6: 1.8459 - dense_3_loss_7: 1.8571 - dense_3_loss_8: 1.8365    \n",
      "Epoch 11/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.1075 - dense_3_loss_1: 2.4262 - dense_3_loss_2: 2.2584 - dense_3_loss_3: 2.0672 - dense_3_loss_4: 1.9354 - dense_3_loss_5: 1.8871 - dense_3_loss_6: 1.8443 - dense_3_loss_7: 1.8548 - dense_3_loss_8: 1.8339    \n",
      "Epoch 12/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.1020 - dense_3_loss_1: 2.4255 - dense_3_loss_2: 2.2592 - dense_3_loss_3: 2.0674 - dense_3_loss_4: 1.9342 - dense_3_loss_5: 1.8853 - dense_3_loss_6: 1.8436 - dense_3_loss_7: 1.8544 - dense_3_loss_8: 1.8324    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f865bc48e50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy')\n",
    "mdl.fit([zeros] + train_data, output_data, nb_epoch=12, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:11:53.916370Z",
     "start_time": "2017-11-22T04:11:53.908982Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mdl_predict(seq_3char):\n",
    "    if len(seq_3char) < 8:\n",
    "        padding_len = 8 - len(seq_3char)\n",
    "        padding = '\\0' * padding_len\n",
    "        seq_3char = padding + seq_3char\n",
    "    pred_data = [txt_encoder[i] for i in seq_3char]\n",
    "    arrs = [np.stack([i]) for i in pred_data]\n",
    "    pred = mdl.predict([np.tile(np.zeros(40), (1, 1))] + arrs)\n",
    "    return [txt_decoder[np.argmax(o)] for o in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:11:58.211173Z",
     "start_time": "2017-11-22T04:11:54.932691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[')', ';', ';', ';', ';', ';', ';', ';']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_predict('sufferin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:40:27.585274Z",
     "start_time": "2017-11-22T04:40:27.578255Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(num_chars):\n",
    "    outs = []\n",
    "    base_str = 'Sufferin'\n",
    "    for i in range(num_chars):\n",
    "        prediction = mdl.predict([np.stack(np.zeros(40))[np.newaxis]] +\n",
    "                                          [np.array([txt_encoder[i]]) for i in base_str])\n",
    "        next_char = np.argmax(prediction[-1]) # the final model output\n",
    "        outs.append(txt_decoder[next_char])\n",
    "        base_str = (base_str + txt_decoder[next_char])[-40:]\n",
    "    return base_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:30:13.222761Z",
     "start_time": "2017-11-22T04:30:12.969707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "';S;;S;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:49:51.205977Z",
     "start_time": "2017-11-22T04:49:51.073080Z"
    }
   },
   "outputs": [],
   "source": [
    "inp = Input(batch_shape=(64, seq_len))\n",
    "emb = Embedding(input_dim=vocab_size, output_dim=40, batch_input_shape=(64,seq_len))(inp)\n",
    "bn = BatchNormalization()(emb)\n",
    "rnn = LSTM(output_dim=256, activation='relu', return_sequences=True, stateful=True)(bn)\n",
    "bn2 = BatchNormalization()(rnn)\n",
    "d = Dropout(0.2)(bn2)\n",
    "out = TimeDistributed(Dense(vocab_size, activation='softmax'))(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:49:51.942500Z",
     "start_time": "2017-11-22T04:49:51.939212Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl2 = Model(input=inp, output=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:49:52.612813Z",
     "start_time": "2017-11-22T04:49:52.598996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl2.compile(optimizer=Adam(lr=1e-5), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:49:53.299209Z",
     "start_time": "2017-11-22T04:49:53.284888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12800, 40), (12800, 40, 1))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stateful = np.stack(np.squeeze(train_data), axis=1)[:12800]\n",
    "y_stateful = np.atleast_3d(np.stack(output_data, axis=1))[:12800]\n",
    "\n",
    "x_stateful.shape, y_stateful.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:52:07.212986Z",
     "start_time": "2017-11-22T04:49:58.468992Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: 4.9137    \n",
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: 4.4854    \n",
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: 4.1476    \n",
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: 3.8951    \n",
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: 3.6955    \n",
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: 3.5340    \n",
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: nan    \n",
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: nan    \n",
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: nan    \n",
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: nan    \n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "for i in range(n_epoch):\n",
    "    mdl2.reset_states()\n",
    "    mdl2.fit(x_stateful, y_stateful, nb_epoch=1, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:41:08.877572Z",
     "start_time": "2017-11-22T04:40:45.843063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "12800/12800 [==============================] - 11s - loss: nan    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7b3936550>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl2.compile(optimizer=Adam(lr=1e-4), loss='sparse_categorical_crossentropy')\n",
    "mdl2.fit(x_stateful, y_stateful, nb_epoch=1, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:53:21.370540Z",
     "start_time": "2017-11-22T04:53:21.363322Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(num_chars):\n",
    "    outs = []\n",
    "    base_str = 'Sufferin'\n",
    "    for i in range(num_chars):\n",
    "        prediction = mdl2.predict(np.array([txt_encoder[i] for i in base_str])[np.newaxis])\n",
    "        next_char = np.argmax(prediction[-1]) # the final model output\n",
    "        outs.append(txt_decoder[next_char])\n",
    "        base_str = (base_str + txt_decoder[next_char])[-8:]\n",
    "    return ''.join(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:53:28.278384Z",
     "start_time": "2017-11-22T04:53:28.245225Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_16 to have shape (64, 40) but got array with shape (1, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-c89d02878bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-140-16ddde603120>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(num_chars)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbase_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Sufferin'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtxt_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the final model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1252\u001b[0m         x = standardize_input_data(x, self.input_names,\n\u001b[1;32m   1253\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                                    check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected input_16 to have shape (64, 40) but got array with shape (1, 8)"
     ]
    }
   ],
   "source": [
    "generate_text(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
