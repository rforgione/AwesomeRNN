{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:37:43.396836Z",
     "start_time": "2017-11-21T22:37:41.624792Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, SimpleRNN, Dense, merge, Flatten, BatchNormalization, LSTM, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import urllib2\n",
    "import numpy as np\n",
    "\n",
    "dataset_raw = urllib2.urlopen(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\").read().\\\n",
    "    replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:02:12.384036Z",
     "start_time": "2017-11-21T22:02:12.331881Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = sorted(list(set([i for i in dataset_raw])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:02:16.735826Z",
     "start_time": "2017-11-21T22:02:16.732895Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:02:30.824782Z",
     "start_time": "2017-11-21T22:02:30.820904Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt_encoder = {v:k for k,v in enumerate(vocab)}\n",
    "txt_decoder = {k:v for k,v in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:02:35.316675Z",
     "start_time": "2017-11-21T22:02:35.260727Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_encoded = [txt_encoder[i] for i in dataset_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:02:43.031743Z",
     "start_time": "2017-11-21T22:02:43.028943Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:02:48.343836Z",
     "start_time": "2017-11-21T22:02:48.341070Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:03:05.569370Z",
     "start_time": "2017-11-21T22:03:04.552774Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = [np.stack([dataset_encoded[i + j] for i in range(0, len(dataset_raw) - seq_len - 1, seq_len)]) for j in range(seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:03:23.967305Z",
     "start_time": "2017-11-21T22:03:22.949217Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_data = [np.stack([dataset_encoded[i + j]\n",
    "                         for i in range(0, len(dataset_raw) - seq_len - 1, seq_len)])[:,np.newaxis] \n",
    "                         for j in range(1, seq_len + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:03:34.742203Z",
     "start_time": "2017-11-21T22:03:34.676111Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inps = []\n",
    "embs = []\n",
    "\n",
    "for i in range(seq_len):\n",
    "    inps.append(Input(shape=(1,), name='inp_%s' % i))\n",
    "    embs.append(Flatten()(Embedding(input_dim=vocab_size, output_dim=40, name='emb_%s' % i)(inps[i])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:03:45.623934Z",
     "start_time": "2017-11-21T22:03:45.621209Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:03:49.633490Z",
     "start_time": "2017-11-21T22:03:49.629433Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(hidden_layer_size, activation='relu')\n",
    "dense_hidden = Dense(hidden_layer_size, activation='relu', init='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:03:57.609312Z",
     "start_time": "2017-11-21T22:03:57.530770Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs = []\n",
    "\n",
    "zero_inp = Input(shape=(40,), name='zeros')\n",
    "hidden = dense_in(zero_inp)\n",
    "\n",
    "for i in range(seq_len):\n",
    "    bn = BatchNormalization()(embs[i])\n",
    "    din = dense_in(bn)\n",
    "    hidden = merge([din, dense_hidden(hidden)])\n",
    "    outs.append(dense_out(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:04:12.575489Z",
     "start_time": "2017-11-21T22:04:12.564640Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeros = np.tile(np.zeros(40), (len(train_data[0]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:04:16.908219Z",
     "start_time": "2017-11-21T22:04:16.902868Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl = Model(input=[zero_inp] + [i for i in inps], output=outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:04:21.757170Z",
     "start_time": "2017-11-21T22:04:21.678911Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl.compile(optimizer=Adam(lr=0.00001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:08:35.190349Z",
     "start_time": "2017-11-21T22:04:30.438472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75112/75112 [==============================] - 15s - loss: 28.6928 - dense_3_loss_1: 4.2481 - dense_3_loss_2: 4.0295 - dense_3_loss_3: 3.7415 - dense_3_loss_4: 3.4701 - dense_3_loss_5: 3.3294 - dense_3_loss_6: 3.2722 - dense_3_loss_7: 3.2750 - dense_3_loss_8: 3.3271    \n",
      "Epoch 2/12\n",
      "75112/75112 [==============================] - 15s - loss: 25.7862 - dense_3_loss_1: 3.9131 - dense_3_loss_2: 3.5009 - dense_3_loss_3: 3.1995 - dense_3_loss_4: 3.0287 - dense_3_loss_5: 3.0105 - dense_3_loss_6: 3.0168 - dense_3_loss_7: 3.0476 - dense_3_loss_8: 3.0690    \n",
      "Epoch 3/12\n",
      "75112/75112 [==============================] - 15s - loss: 24.4473 - dense_3_loss_1: 3.6158 - dense_3_loss_2: 3.1935 - dense_3_loss_3: 3.0057 - dense_3_loss_4: 2.9193 - dense_3_loss_5: 2.9235 - dense_3_loss_6: 2.9200 - dense_3_loss_7: 2.9370 - dense_3_loss_8: 2.9325    \n",
      "Epoch 4/12\n",
      "75112/75112 [==============================] - 15s - loss: 23.3779 - dense_3_loss_1: 3.3494 - dense_3_loss_2: 2.9923 - dense_3_loss_3: 2.8867 - dense_3_loss_4: 2.8303 - dense_3_loss_5: 2.8400 - dense_3_loss_6: 2.8233 - dense_3_loss_7: 2.8334 - dense_3_loss_8: 2.8225    \n",
      "Epoch 5/12\n",
      "75112/75112 [==============================] - 15s - loss: 22.4873 - dense_3_loss_1: 3.1296 - dense_3_loss_2: 2.8581 - dense_3_loss_3: 2.7945 - dense_3_loss_4: 2.7477 - dense_3_loss_5: 2.7575 - dense_3_loss_6: 2.7326 - dense_3_loss_7: 2.7390 - dense_3_loss_8: 2.7283    \n",
      "Epoch 6/12\n",
      "75112/75112 [==============================] - 15s - loss: 21.7812 - dense_3_loss_1: 2.9648 - dense_3_loss_2: 2.7609 - dense_3_loss_3: 2.7164 - dense_3_loss_4: 2.6770 - dense_3_loss_5: 2.6836 - dense_3_loss_6: 2.6593 - dense_3_loss_7: 2.6637 - dense_3_loss_8: 2.6556    \n",
      "Epoch 7/12\n",
      "75112/75112 [==============================] - 15s - loss: 21.2460 - dense_3_loss_1: 2.8496 - dense_3_loss_2: 2.6878 - dense_3_loss_3: 2.6546 - dense_3_loss_4: 2.6198 - dense_3_loss_5: 2.6243 - dense_3_loss_6: 2.6034 - dense_3_loss_7: 2.6060 - dense_3_loss_8: 2.6005    \n",
      "Epoch 8/12\n",
      "75112/75112 [==============================] - 15s - loss: 20.8445 - dense_3_loss_1: 2.7716 - dense_3_loss_2: 2.6315 - dense_3_loss_3: 2.6061 - dense_3_loss_4: 2.5755 - dense_3_loss_5: 2.5772 - dense_3_loss_6: 2.5618 - dense_3_loss_7: 2.5639 - dense_3_loss_8: 2.5571    \n",
      "Epoch 9/12\n",
      "75112/75112 [==============================] - 15s - loss: 20.5406 - dense_3_loss_1: 2.7180 - dense_3_loss_2: 2.5910 - dense_3_loss_3: 2.5687 - dense_3_loss_4: 2.5394 - dense_3_loss_5: 2.5396 - dense_3_loss_6: 2.5283 - dense_3_loss_7: 2.5316 - dense_3_loss_8: 2.5240    \n",
      "Epoch 10/12\n",
      "75112/75112 [==============================] - 15s - loss: 20.2932 - dense_3_loss_1: 2.6796 - dense_3_loss_2: 2.5594 - dense_3_loss_3: 2.5375 - dense_3_loss_4: 2.5095 - dense_3_loss_5: 2.5094 - dense_3_loss_6: 2.4996 - dense_3_loss_7: 2.5039 - dense_3_loss_8: 2.4942    \n",
      "Epoch 11/12\n",
      "75112/75112 [==============================] - 15s - loss: 20.0910 - dense_3_loss_1: 2.6515 - dense_3_loss_2: 2.5352 - dense_3_loss_3: 2.5105 - dense_3_loss_4: 2.4844 - dense_3_loss_5: 2.4832 - dense_3_loss_6: 2.4758 - dense_3_loss_7: 2.4808 - dense_3_loss_8: 2.4696    \n",
      "Epoch 12/12\n",
      "75112/75112 [==============================] - 15s - loss: 19.9205 - dense_3_loss_1: 2.6292 - dense_3_loss_2: 2.5150 - dense_3_loss_3: 2.4881 - dense_3_loss_4: 2.4630 - dense_3_loss_5: 2.4617 - dense_3_loss_6: 2.4547 - dense_3_loss_7: 2.4608 - dense_3_loss_8: 2.4480    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8672b96590>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit([zeros] + train_data, output_data, nb_epoch=12, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:12:29.994836Z",
     "start_time": "2017-11-21T22:09:05.431145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75112/75112 [==============================] - 15s - loss: 19.3652 - dense_3_loss_1: 2.5690 - dense_3_loss_2: 2.4519 - dense_3_loss_3: 2.4105 - dense_3_loss_4: 2.3885 - dense_3_loss_5: 2.3888 - dense_3_loss_6: 2.3814 - dense_3_loss_7: 2.3944 - dense_3_loss_8: 2.3807    \n",
      "Epoch 2/12\n",
      "75112/75112 [==============================] - 15s - loss: 18.6464 - dense_3_loss_1: 2.5130 - dense_3_loss_2: 2.3812 - dense_3_loss_3: 2.3194 - dense_3_loss_4: 2.2896 - dense_3_loss_5: 2.2908 - dense_3_loss_6: 2.2800 - dense_3_loss_7: 2.2927 - dense_3_loss_8: 2.2797    \n",
      "Epoch 3/12\n",
      "75112/75112 [==============================] - 15s - loss: 18.1987 - dense_3_loss_1: 2.4889 - dense_3_loss_2: 2.3438 - dense_3_loss_3: 2.2663 - dense_3_loss_4: 2.2265 - dense_3_loss_5: 2.2253 - dense_3_loss_6: 2.2118 - dense_3_loss_7: 2.2259 - dense_3_loss_8: 2.2102    \n",
      "Epoch 4/12\n",
      "75112/75112 [==============================] - 15s - loss: 17.8806 - dense_3_loss_1: 2.4754 - dense_3_loss_2: 2.3204 - dense_3_loss_3: 2.2300 - dense_3_loss_4: 2.1831 - dense_3_loss_5: 2.1787 - dense_3_loss_6: 2.1593 - dense_3_loss_7: 2.1755 - dense_3_loss_8: 2.1582    \n",
      "Epoch 5/12\n",
      "75112/75112 [==============================] - 15s - loss: 17.6452 - dense_3_loss_1: 2.4673 - dense_3_loss_2: 2.3075 - dense_3_loss_3: 2.2044 - dense_3_loss_4: 2.1494 - dense_3_loss_5: 2.1413 - dense_3_loss_6: 2.1207 - dense_3_loss_7: 2.1365 - dense_3_loss_8: 2.1181    \n",
      "Epoch 6/12\n",
      "75112/75112 [==============================] - 15s - loss: 17.4623 - dense_3_loss_1: 2.4624 - dense_3_loss_2: 2.2976 - dense_3_loss_3: 2.1850 - dense_3_loss_4: 2.1242 - dense_3_loss_5: 2.1137 - dense_3_loss_6: 2.0903 - dense_3_loss_7: 2.1035 - dense_3_loss_8: 2.0855    \n",
      "Epoch 7/12\n",
      "75112/75112 [==============================] - 15s - loss: 17.3065 - dense_3_loss_1: 2.4579 - dense_3_loss_2: 2.2904 - dense_3_loss_3: 2.1674 - dense_3_loss_4: 2.1018 - dense_3_loss_5: 2.0895 - dense_3_loss_6: 2.0643 - dense_3_loss_7: 2.0773 - dense_3_loss_8: 2.0581    \n",
      "Epoch 8/12\n",
      "75112/75112 [==============================] - 15s - loss: 17.1732 - dense_3_loss_1: 2.4540 - dense_3_loss_2: 2.2858 - dense_3_loss_3: 2.1546 - dense_3_loss_4: 2.0840 - dense_3_loss_5: 2.0669 - dense_3_loss_6: 2.0414 - dense_3_loss_7: 2.0529 - dense_3_loss_8: 2.0336    \n",
      "Epoch 9/12\n",
      "75112/75112 [==============================] - 14s - loss: 17.0498 - dense_3_loss_1: 2.4521 - dense_3_loss_2: 2.2805 - dense_3_loss_3: 2.1414 - dense_3_loss_4: 2.0668 - dense_3_loss_5: 2.0481 - dense_3_loss_6: 2.0207 - dense_3_loss_7: 2.0304 - dense_3_loss_8: 2.0099    \n",
      "Epoch 10/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.9370 - dense_3_loss_1: 2.4493 - dense_3_loss_2: 2.2768 - dense_3_loss_3: 2.1310 - dense_3_loss_4: 2.0507 - dense_3_loss_5: 2.0279 - dense_3_loss_6: 2.0014 - dense_3_loss_7: 2.0105 - dense_3_loss_8: 1.9895    \n",
      "Epoch 11/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.8428 - dense_3_loss_1: 2.4488 - dense_3_loss_2: 2.2746 - dense_3_loss_3: 2.1229 - dense_3_loss_4: 2.0394 - dense_3_loss_5: 2.0116 - dense_3_loss_6: 1.9831 - dense_3_loss_7: 1.9914 - dense_3_loss_8: 1.9710    \n",
      "Epoch 12/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.7508 - dense_3_loss_1: 2.4461 - dense_3_loss_2: 2.2717 - dense_3_loss_3: 2.1148 - dense_3_loss_4: 2.0250 - dense_3_loss_5: 1.9974 - dense_3_loss_6: 1.9674 - dense_3_loss_7: 1.9753 - dense_3_loss_8: 1.9532    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f865e509490>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.compile(optimizer=Adam(lr=0.0001), loss='sparse_categorical_crossentropy')\n",
    "mdl.fit([zeros] + train_data, output_data, nb_epoch=12, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:24:37.760282Z",
     "start_time": "2017-11-21T22:21:20.993496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75112/75112 [==============================] - 15s - loss: 18.7042 - dense_3_loss_1: 2.5083 - dense_3_loss_2: 2.3797 - dense_3_loss_3: 2.3180 - dense_3_loss_4: 2.2843 - dense_3_loss_5: 2.3040 - dense_3_loss_6: 2.2955 - dense_3_loss_7: 2.3150 - dense_3_loss_8: 2.2993    \n",
      "Epoch 2/12\n",
      "75112/75112 [==============================] - 14s - loss: 17.4989 - dense_3_loss_1: 2.4632 - dense_3_loss_2: 2.3154 - dense_3_loss_3: 2.1877 - dense_3_loss_4: 2.1194 - dense_3_loss_5: 2.1143 - dense_3_loss_6: 2.0968 - dense_3_loss_7: 2.1094 - dense_3_loss_8: 2.0927    \n",
      "Epoch 3/12\n",
      "75112/75112 [==============================] - 14s - loss: 17.2581 - dense_3_loss_1: 2.4592 - dense_3_loss_2: 2.3099 - dense_3_loss_3: 2.1657 - dense_3_loss_4: 2.0840 - dense_3_loss_5: 2.0709 - dense_3_loss_6: 2.0515 - dense_3_loss_7: 2.0681 - dense_3_loss_8: 2.0488    \n",
      "Epoch 4/12\n",
      "75112/75112 [==============================] - 14s - loss: 17.0941 - dense_3_loss_1: 2.4557 - dense_3_loss_2: 2.3046 - dense_3_loss_3: 2.1515 - dense_3_loss_4: 2.0622 - dense_3_loss_5: 2.0410 - dense_3_loss_6: 2.0221 - dense_3_loss_7: 2.0380 - dense_3_loss_8: 2.0188    \n",
      "Epoch 5/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.9848 - dense_3_loss_1: 2.4520 - dense_3_loss_2: 2.3014 - dense_3_loss_3: 2.1413 - dense_3_loss_4: 2.0464 - dense_3_loss_5: 2.0252 - dense_3_loss_6: 2.0002 - dense_3_loss_7: 2.0189 - dense_3_loss_8: 1.9994    \n",
      "Epoch 6/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.9204 - dense_3_loss_1: 2.4502 - dense_3_loss_2: 2.2980 - dense_3_loss_3: 2.1360 - dense_3_loss_4: 2.0394 - dense_3_loss_5: 2.0153 - dense_3_loss_6: 1.9876 - dense_3_loss_7: 2.0059 - dense_3_loss_8: 1.9880    \n",
      "Epoch 7/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.8771 - dense_3_loss_1: 2.4505 - dense_3_loss_2: 2.2997 - dense_3_loss_3: 2.1326 - dense_3_loss_4: 2.0327 - dense_3_loss_5: 2.0061 - dense_3_loss_6: 1.9800 - dense_3_loss_7: 1.9977 - dense_3_loss_8: 1.9779    \n",
      "Epoch 8/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.8175 - dense_3_loss_1: 2.4492 - dense_3_loss_2: 2.2947 - dense_3_loss_3: 2.1264 - dense_3_loss_4: 2.0258 - dense_3_loss_5: 1.9980 - dense_3_loss_6: 1.9691 - dense_3_loss_7: 1.9862 - dense_3_loss_8: 1.9680    \n",
      "Epoch 9/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.7840 - dense_3_loss_1: 2.4485 - dense_3_loss_2: 2.2949 - dense_3_loss_3: 2.1264 - dense_3_loss_4: 2.0218 - dense_3_loss_5: 1.9901 - dense_3_loss_6: 1.9579 - dense_3_loss_7: 1.9797 - dense_3_loss_8: 1.9647    \n",
      "Epoch 10/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.7327 - dense_3_loss_1: 2.4478 - dense_3_loss_2: 2.2924 - dense_3_loss_3: 2.1228 - dense_3_loss_4: 2.0132 - dense_3_loss_5: 1.9827 - dense_3_loss_6: 1.9536 - dense_3_loss_7: 1.9705 - dense_3_loss_8: 1.9496    \n",
      "Epoch 11/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.7014 - dense_3_loss_1: 2.4463 - dense_3_loss_2: 2.2895 - dense_3_loss_3: 2.1212 - dense_3_loss_4: 2.0124 - dense_3_loss_5: 1.9764 - dense_3_loss_6: 1.9460 - dense_3_loss_7: 1.9615 - dense_3_loss_8: 1.9481    \n",
      "Epoch 12/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.6831 - dense_3_loss_1: 2.4467 - dense_3_loss_2: 2.2893 - dense_3_loss_3: 2.1207 - dense_3_loss_4: 2.0085 - dense_3_loss_5: 1.9748 - dense_3_loss_6: 1.9425 - dense_3_loss_7: 1.9604 - dense_3_loss_8: 1.9402    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f865a3911d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.compile(optimizer=Adam(lr=0.01), loss='sparse_categorical_crossentropy')\n",
    "mdl.fit([zeros] + train_data, output_data, nb_epoch=12, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:32:28.897568Z",
     "start_time": "2017-11-21T22:29:05.340836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.3331 - dense_3_loss_1: 2.4323 - dense_3_loss_2: 2.2662 - dense_3_loss_3: 2.0841 - dense_3_loss_4: 1.9621 - dense_3_loss_5: 1.9194 - dense_3_loss_6: 1.8863 - dense_3_loss_7: 1.9009 - dense_3_loss_8: 1.8819    \n",
      "Epoch 2/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.2417 - dense_3_loss_1: 2.4299 - dense_3_loss_2: 2.2624 - dense_3_loss_3: 2.0759 - dense_3_loss_4: 1.9511 - dense_3_loss_5: 1.9065 - dense_3_loss_6: 1.8687 - dense_3_loss_7: 1.8830 - dense_3_loss_8: 1.8642    \n",
      "Epoch 3/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.2094 - dense_3_loss_1: 2.4286 - dense_3_loss_2: 2.2617 - dense_3_loss_3: 2.0729 - dense_3_loss_4: 1.9471 - dense_3_loss_5: 1.9016 - dense_3_loss_6: 1.8637 - dense_3_loss_7: 1.8760 - dense_3_loss_8: 1.8580    \n",
      "Epoch 4/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.1919 - dense_3_loss_1: 2.4282 - dense_3_loss_2: 2.2610 - dense_3_loss_3: 2.0722 - dense_3_loss_4: 1.9450 - dense_3_loss_5: 1.8993 - dense_3_loss_6: 1.8602 - dense_3_loss_7: 1.8721 - dense_3_loss_8: 1.8537    \n",
      "Epoch 5/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.1733 - dense_3_loss_1: 2.4279 - dense_3_loss_2: 2.2602 - dense_3_loss_3: 2.0712 - dense_3_loss_4: 1.9429 - dense_3_loss_5: 1.8960 - dense_3_loss_6: 1.8564 - dense_3_loss_7: 1.8692 - dense_3_loss_8: 1.8495    \n",
      "Epoch 6/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.1602 - dense_3_loss_1: 2.4274 - dense_3_loss_2: 2.2596 - dense_3_loss_3: 2.0704 - dense_3_loss_4: 1.9411 - dense_3_loss_5: 1.8943 - dense_3_loss_6: 1.8547 - dense_3_loss_7: 1.8668 - dense_3_loss_8: 1.8459    \n",
      "Epoch 7/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.1485 - dense_3_loss_1: 2.4271 - dense_3_loss_2: 2.2595 - dense_3_loss_3: 2.0698 - dense_3_loss_4: 1.9391 - dense_3_loss_5: 1.8922 - dense_3_loss_6: 1.8521 - dense_3_loss_7: 1.8649 - dense_3_loss_8: 1.8437    \n",
      "Epoch 8/12\n",
      "75112/75112 [==============================] - 15s - loss: 16.1352 - dense_3_loss_1: 2.4271 - dense_3_loss_2: 2.2593 - dense_3_loss_3: 2.0689 - dense_3_loss_4: 1.9381 - dense_3_loss_5: 1.8903 - dense_3_loss_6: 1.8496 - dense_3_loss_7: 1.8621 - dense_3_loss_8: 1.8399    \n",
      "Epoch 9/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.1264 - dense_3_loss_1: 2.4266 - dense_3_loss_2: 2.2589 - dense_3_loss_3: 2.0683 - dense_3_loss_4: 1.9372 - dense_3_loss_5: 1.8897 - dense_3_loss_6: 1.8476 - dense_3_loss_7: 1.8594 - dense_3_loss_8: 1.8386    \n",
      "Epoch 10/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.1162 - dense_3_loss_1: 2.4263 - dense_3_loss_2: 2.2590 - dense_3_loss_3: 2.0683 - dense_3_loss_4: 1.9353 - dense_3_loss_5: 1.8877 - dense_3_loss_6: 1.8459 - dense_3_loss_7: 1.8571 - dense_3_loss_8: 1.8365    \n",
      "Epoch 11/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.1075 - dense_3_loss_1: 2.4262 - dense_3_loss_2: 2.2584 - dense_3_loss_3: 2.0672 - dense_3_loss_4: 1.9354 - dense_3_loss_5: 1.8871 - dense_3_loss_6: 1.8443 - dense_3_loss_7: 1.8548 - dense_3_loss_8: 1.8339    \n",
      "Epoch 12/12\n",
      "75112/75112 [==============================] - 14s - loss: 16.1020 - dense_3_loss_1: 2.4255 - dense_3_loss_2: 2.2592 - dense_3_loss_3: 2.0674 - dense_3_loss_4: 1.9342 - dense_3_loss_5: 1.8853 - dense_3_loss_6: 1.8436 - dense_3_loss_7: 1.8544 - dense_3_loss_8: 1.8324    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f865bc48e50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy')\n",
    "mdl.fit([zeros] + train_data, output_data, nb_epoch=12, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:32:37.975688Z",
     "start_time": "2017-11-21T22:32:37.968284Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mdl_predict(seq_3char):\n",
    "    if len(seq_3char) < 8:\n",
    "        padding_len = 8 - len(seq_3char)\n",
    "        padding = '\\0' * padding_len\n",
    "        seq_3char = padding + seq_3char\n",
    "    pred_data = [txt_encoder[i] for i in seq_3char]\n",
    "    arrs = [np.stack([i]) for i in pred_data]\n",
    "    pred = mdl.predict([np.tile(np.zeros(40), (1, 1))] + arrs)\n",
    "    return [txt_decoder[np.argmax(o)] for o in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:32:40.831619Z",
     "start_time": "2017-11-21T22:32:38.372889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', 'l', 'f', 'e', 'r', 'e', 'n', 'g']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_predict('sufferin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:32:52.523484Z",
     "start_time": "2017-11-21T22:32:52.516576Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(num_chars):\n",
    "    outs = []\n",
    "    base_str = 'Sufferin'\n",
    "    for i in range(num_chars):\n",
    "        prediction = mdl.predict([np.stack(np.zeros(40))[np.newaxis]] +\n",
    "                                          [np.array([txt_encoder[i]]) for i in base_str])\n",
    "        next_char = np.argmax(prediction[-1]) # the final model output\n",
    "        outs.append(txt_decoder[next_char])\n",
    "        base_str = (base_str + txt_decoder[next_char])[-8:]\n",
    "    return ''.join(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T22:33:02.230279Z",
     "start_time": "2017-11-21T22:33:01.980086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g and the sermen the sermen the sermen the sermen the sermen the sermen the sermen the sermen the se'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:05:54.272952Z",
     "start_time": "2017-11-21T23:05:54.180324Z"
    }
   },
   "outputs": [],
   "source": [
    "inp = Input(batch_shape=(64,8))\n",
    "emb = Embedding(input_dim=vocab_size, output_dim=40, batch_input_shape=(64,8))(inp)\n",
    "bn = BatchNormalization()(emb)\n",
    "rnn = LSTM(output_dim=256, activation='relu', return_sequences=True, stateful=True)(bn)\n",
    "out = TimeDistributed(Dense(256, activation='softmax'))(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:05:55.070674Z",
     "start_time": "2017-11-21T23:05:55.066442Z"
    }
   },
   "outputs": [],
   "source": [
    "mdl2 = Model(input=inp, output=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:05:55.781960Z",
     "start_time": "2017-11-21T23:05:55.761769Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl2.compile(optimizer=Adam(lr=1e-6), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:05:56.256651Z",
     "start_time": "2017-11-21T23:05:56.244906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64000, 8), (64000, 8, 1))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stateful = np.stack(np.squeeze(train_data), axis=1)[:64000]\n",
    "y_stateful = np.atleast_3d(np.stack(output_data, axis=1))[:64000]\n",
    "\n",
    "x_stateful.shape, y_stateful.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:06:55.948300Z",
     "start_time": "2017-11-21T23:05:56.805003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "64000/64000 [==============================] - 14s - loss: 5.4646    \n",
      "Epoch 2/4\n",
      "64000/64000 [==============================] - 13s - loss: nan    \n",
      "Epoch 3/4\n",
      "64000/64000 [==============================] - 13s - loss: nan    \n",
      "Epoch 4/4\n",
      "24640/64000 [==========>...................] - ETA: 8s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-8951f1ed178b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmdl2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    987\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mdl2.fit(x_stateful, y_stateful, nb_epoch=4, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(num_chars):\n",
    "    outs = []\n",
    "    base_str = 'Sufferin'\n",
    "    for i in range(num_chars):\n",
    "        prediction = mdl2.predict([np.stack(np.zeros(40))[np.newaxis]] +\n",
    "                                          [np.array([txt_encoder[i]]) for i in base_str])\n",
    "        next_char = np.argmax(prediction[-1]) # the final model output\n",
    "        outs.append(txt_decoder[next_char])\n",
    "        base_str = (base_str + txt_decoder[next_char])[-8:]\n",
    "    return ''.join(outs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
